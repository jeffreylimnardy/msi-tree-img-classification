{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Classification with Deep Neural Network / Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "The dataset preprocessing includes loading the raw npy dataset that has been created with the convertToNpy.py script. The loaded data is then separated into the X (input array) and Y (ground truth label). The input array is then normalized using the min-max scaler which is implemented in the NormalizeMatrix function. Then the data is split into training, validation, and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35682, 10, 5, 5)\n",
      "(35682,)\n",
      "8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1050'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from TreeDataset import TreeDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "from torch.nn import init\n",
    "import torchvision.models as models\n",
    "\n",
    "#convert image matrix to a numpy array and feed it into dataset\n",
    "\n",
    "image = np.load(\"assets/data_without_label.npy\")\n",
    "labels = np.load(\"assets/labels.npy\",allow_pickle = True)\n",
    "\n",
    "print(image.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(labels)\n",
    "\n",
    "print(np.count_nonzero(encoded_labels == 4))\n",
    "\n",
    "dataset = TreeDataset(image, encoded_labels)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28545\n"
     ]
    }
   ],
   "source": [
    "# Define the ratio of the split (e.g., 80% for training, 20% for testing)\n",
    "train_val_ratio = 0.8\n",
    "test_ratio = 1 - train_val_ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "num_samples = len(dataset)\n",
    "train_val_size = int(train_val_ratio * num_samples)\n",
    "test_size = num_samples - train_val_size\n",
    "\n",
    "train_size = int(train_ratio * train_val_size)\n",
    "val_size = train_val_size - train_size\n",
    "\n",
    "print(train_val_size)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "val_generator = torch.Generator().manual_seed(18)\n",
    "\n",
    "# Randomly split the dataset into training and test sets\n",
    "train_val_dataset, test_dataset = random_split(dataset, [train_val_size, test_size],generator=generator)\n",
    "      \n",
    "train_dataset, val_dataset = random_split(train_val_dataset,[train_size, val_size], generator=val_generator )\n",
    "\n",
    "# Create data loaders for the training and test sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be solved??\n",
    "# Current data shape (num_data, num_channels, pixel_row, pixel_col)\n",
    "\n",
    "from models import ModifiedResNet, MultispectralClassifier, MyNet, ResidualBlock\n",
    "\n",
    "# cnnModel = ModifiedResNet(ResidualBlock, [3, 4, 6, 3])\n",
    "\n",
    "cnnModel = MultispectralClassifier(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnnModel.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate Loss\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in valid_loader:\n",
    "        # Transfer Data to GPU if available\n",
    "        data, labels = data.float(), labels.long()\n",
    "        # Forward Pass\n",
    "        target = model(data.float())\n",
    "        # Find the Loss\n",
    "        valid_loss = loss_fn(target,labels)\n",
    "        if batch % 100 == 0:\n",
    "            valid_loss = valid_loss.item()\n",
    "            print(f\"Valid_loss: {valid_loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y.long()).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.040650  [   32/22836]\n",
      "loss: 2.188697  [ 3232/22836]\n",
      "loss: 2.072292  [ 6432/22836]\n",
      "loss: 2.083125  [ 9632/22836]\n",
      "loss: 2.035035  [12832/22836]\n",
      "loss: 2.085088  [16032/22836]\n",
      "loss: 2.072678  [19232/22836]\n",
      "loss: 2.267495  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.094500 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.962896  [   32/22836]\n",
      "loss: 2.082603  [ 3232/22836]\n",
      "loss: 2.166827  [ 6432/22836]\n",
      "loss: 1.970408  [ 9632/22836]\n",
      "loss: 2.055088  [12832/22836]\n",
      "loss: 2.071980  [16032/22836]\n",
      "loss: 1.933033  [19232/22836]\n",
      "loss: 2.010544  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.095809 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.159023  [   32/22836]\n",
      "loss: 2.155641  [ 3232/22836]\n",
      "loss: 2.006169  [ 6432/22836]\n",
      "loss: 1.996036  [ 9632/22836]\n",
      "loss: 2.055849  [12832/22836]\n",
      "loss: 1.999364  [16032/22836]\n",
      "loss: 1.931964  [19232/22836]\n",
      "loss: 2.049407  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.092902 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.002706  [   32/22836]\n",
      "loss: 2.004484  [ 3232/22836]\n",
      "loss: 2.033207  [ 6432/22836]\n",
      "loss: 2.118280  [ 9632/22836]\n",
      "loss: 2.054076  [12832/22836]\n",
      "loss: 1.763919  [16032/22836]\n",
      "loss: 2.024325  [19232/22836]\n",
      "loss: 1.959545  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.092110 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.085953  [   32/22836]\n",
      "loss: 2.237656  [ 3232/22836]\n",
      "loss: 2.005463  [ 6432/22836]\n",
      "loss: 2.001985  [ 9632/22836]\n",
      "loss: 1.941681  [12832/22836]\n",
      "loss: 2.146104  [16032/22836]\n",
      "loss: 1.948407  [19232/22836]\n",
      "loss: 2.047630  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.091300 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.091726  [   32/22836]\n",
      "loss: 2.129191  [ 3232/22836]\n",
      "loss: 1.895340  [ 6432/22836]\n",
      "loss: 2.135994  [ 9632/22836]\n",
      "loss: 2.072440  [12832/22836]\n",
      "loss: 2.249674  [16032/22836]\n",
      "loss: 2.236797  [19232/22836]\n",
      "loss: 2.110295  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.094398 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.986109  [   32/22836]\n",
      "loss: 2.138137  [ 3232/22836]\n",
      "loss: 1.901996  [ 6432/22836]\n",
      "loss: 2.232154  [ 9632/22836]\n",
      "loss: 2.128978  [12832/22836]\n",
      "loss: 2.099802  [16032/22836]\n",
      "loss: 2.057216  [19232/22836]\n",
      "loss: 1.899627  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.092250 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.014134  [   32/22836]\n",
      "loss: 2.160809  [ 3232/22836]\n",
      "loss: 2.171011  [ 6432/22836]\n",
      "loss: 2.177365  [ 9632/22836]\n",
      "loss: 2.223011  [12832/22836]\n",
      "loss: 2.063928  [16032/22836]\n",
      "loss: 1.986184  [19232/22836]\n",
      "loss: 2.320215  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.091387 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.217543  [   32/22836]\n",
      "loss: 2.223642  [ 3232/22836]\n",
      "loss: 1.992150  [ 6432/22836]\n",
      "loss: 1.966278  [ 9632/22836]\n",
      "loss: 2.096539  [12832/22836]\n",
      "loss: 2.177462  [16032/22836]\n",
      "loss: 2.030885  [19232/22836]\n",
      "loss: 1.930722  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.093536 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.968249  [   32/22836]\n",
      "loss: 2.013810  [ 3232/22836]\n",
      "loss: 2.011327  [ 6432/22836]\n",
      "loss: 2.107092  [ 9632/22836]\n",
      "loss: 1.976414  [12832/22836]\n",
      "loss: 2.098370  [16032/22836]\n",
      "loss: 1.943326  [19232/22836]\n",
      "loss: 1.861888  [22432/22836]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.091707 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, cnnModel, loss_fn, optimizer)\n",
    "    test_loop(test_loader, cnnModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 23 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "label_collector = []\n",
    "prediction_collector = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = cnnModel(images.float())\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        label_collector.append(labels)\n",
    "        prediction_collector.append(predicted)\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "#cm = confusion_matrix(prediction_collector, label_collector )\n",
    "#ConfusionMatrixDisplay(cm).plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778],\n",
      "        [-0.3199, -0.0168,  0.4432, -0.9538,  0.8621,  0.7535, -1.0501, -0.7594,\n",
      "         -0.6650, -0.3778]], grad_fn=<AddmmBackward0>)\n",
      "tensor([False,  True, False, False, False, False,  True,  True,  True,  True,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "inputs, classes = next(iter(test_loader))\n",
    "\n",
    "output = cnnModel(inputs.float())\n",
    "print(output)\n",
    "\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "\n",
    "print(predicted==classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.save(cnnModel.state_dict(),\"D:\\Programming\\Python\\machinelearning\\DSEO\\MultispectralClassifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MultispectralClassifier                  [32, 10]                  --\n",
       "├─Sequential: 1-1                        [32, 64, 1, 1]            --\n",
       "│    └─Conv2d: 2-1                       [32, 32, 5, 5]            2,912\n",
       "│    └─ReLU: 2-2                         [32, 32, 5, 5]            --\n",
       "│    └─MaxPool2d: 2-3                    [32, 32, 2, 2]            --\n",
       "│    └─Conv2d: 2-4                       [32, 64, 2, 2]            18,496\n",
       "│    └─ReLU: 2-5                         [32, 64, 2, 2]            --\n",
       "│    └─MaxPool2d: 2-6                    [32, 64, 1, 1]            --\n",
       "├─Sequential: 1-2                        [32, 10]                  --\n",
       "│    └─Linear: 2-7                       [32, 128]                 8,320\n",
       "│    └─ReLU: 2-8                         [32, 128]                 --\n",
       "│    └─Linear: 2-9                       [32, 10]                  1,290\n",
       "==========================================================================================\n",
       "Total params: 31,018\n",
       "Trainable params: 31,018\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 5.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 0.31\n",
       "Params size (MB): 0.12\n",
       "Estimated Total Size (MB): 0.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(cnnModel, input_size=(batch_size, 10, 5, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSEO_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
